#data Science
#problem=> Data acquire  => Data pre process => data storage

#python => libraries => Pandas and numpy
#numpy => numerical python
#scientific library => data in form nd array
#[1,2,3,4]

import numpy

type(numpy.arange(4))

                                       output == numpy.ndarray

import numpy as np
arr1=np.arange(5)a
arr1                                   output == array([0, 1, 2, 3, 4])



arr1=np.array([1,2,3])                 output == 3 
arr1.size                               


arr1=np.array([[1,2],[2,3],[5,6]])
print( arr1.size)
print(arr1.shape)
print(arr1.dtype)                      output == 6
                                                (3, 2)
                                                int64


arr2=np.arange(3)
print(arr2.shape)                      output == (3,)



np.ones([3,4])                         output == array([[1., 1., 1., 1.],
                                                        [1., 1., 1., 1.],
                                                        [1., 1., 1., 1.]])



arr1=np.arange(9)
arr1.reshape(3,3)                      output == array([[0, 1, 2],
                                                        [3, 4, 5],
                                                        [6, 7, 8]])



import numpy as np
a = np.array([[1,2], [3,4]])
print(a)                               output == [[1 2]
                                                  [3 4]]


b=a.transpose()
print(b)                               output == [[1 3]
                                                  [2 4]]



import numpy as np
arr1= np.array([[1,2,3],[2,3,4],[4,5,6]])
print(arr1)
arr2=arr1.transpose()
print(arr2)
arr1.shape
                                       output == [[1 2 3]
                                                  [2 3 4]
                                                  [4 5 6]]
                                                  [[1 2 4]
                                                  [2 3 5]
                                                  [3 4 6]]
                                                  (3, 3)



#numpy
#String => conert =>int


# pandas: powerful => data transform , clean, prepare
#series : 1d array
#Dataframe : collection of series tabular format for your data
import pandas
series1=pandas.Series([10,2,34,4])
series1.values                         output == array([10,  2, 34,  4])




series1.index
print(series1[0])  # checking index 0 value 
                                     output == 10



import pandas
series1=pandas.Series([10,2,34,4])
series1[0]=90 #update
series1[5]=1000
series1                                

output ==
 
0
0	90
1	2
2	34
3	4
5	1000

dtype: int64




import pandas as pd
series1=pd.Series([10,2,34,4], index=["A","B","C","D"])
series1.to_dict()


output == {'A': 10, 'B': 2, 'C': 34, 'D': 4}  



arr1 = np.array([10,20,34,56,22])
series1=pd.Series(arr1)
series1.value_counts(ascending= True)



output == 

count
10	1
20	1
34	1
56	1
22	1

dtype: int64


arr1=np.array([10,20,34,56,22])
series1=pd.Series(arr1)
series1.sort_values()



output == 

0
0	10
1	20
4	22
2	34
3	56

dtype: int64


my_dict = {'a': 10, 'b': 20, 'c': 30}
my_series = pd.Series(my_dict)
my_series.drop_duplicates(inplace=True)
print(my_series)

output == 

a    10
b    20
c    30
dtype: int64


data=[[10,12],[13,14]]
df=pd.DataFrame(data, columns=["product1","product2"])

type(df["product1"])


output ==     pandas.core.series.Series
def __init__(data=None, index=None, dtype: Dtype | None=None, name=None, copy: bool | None=None, fastpath: bool | lib.NoDefault=lib.no_default) -> None
One-dimensional ndarray with axis labels (including time series).

Labels need not be unique but must be a hashable type. The object
supports both integer- and label-based indexing and provides a host of
methods for performing operations involving the index. Statistical
methods from ndarray have been overridden to automatically exclude
missing data (currently represented as NaN).

Operations between Series (+, -, /, \*, \*\*) align values based on their
associated index values-- they need not be the same length. The result
index will be the sorted union of the two indexes.

Parameters
----------
data : array-like, Iterable, dict, or scalar value
    Contains data stored in Series. If data is a dict, argument order is
    maintained.
index : array-like or Index (1d)
    Values must be hashable and have the same length as `data`.
    Non-unique index values are allowed. Will default to
    RangeIndex (0, 1, 2, ..., n) if not provided. If data is dict-like
    and index is None, then the keys in the data are used as the index. If the
    index is not None, the resulting Series is reindexed with the index values.
dtype : str, numpy.dtype, or ExtensionDtype, optional
    Data type for the output Series. If not specified, this will be
    inferred from `data`.
    See the :ref:`user guide <basics.dtypes>` for more usages.
name : Hashable, default None
    The name to give to the Series.
copy : bool, default False
    Copy input data. Only affects Series or 1d ndarray input. See examples.

Notes
-----
Please reference the :ref:`User Guide <basics.series>` for more information.

Examples
--------
Constructing Series from a dictionary with an Index specified

>>> d = {'a': 1, 'b': 2, 'c': 3}
>>> ser = pd.Series(data=d, index=['a', 'b', 'c'])
>>> ser
a   1
b   2
c   3
dtype: int64

The keys of the dictionary match with the Index values, hence the Index
values have no effect.

>>> d = {'a': 1, 'b': 2, 'c': 3}
>>> ser = pd.Series(data=d, index=['x', 'y', 'z'])
>>> ser
x   NaN
y   NaN
z   NaN
dtype: float64

Note that the Index is first build with the keys from the dictionary.
After this the Series is reindexed with the given Index values, hence we
get all NaN as a result.

Constructing Series from a list with `copy=False`.

>>> r = [1, 2]
>>> ser = pd.Series(r, copy=False)
>>> ser.iloc[0] = 999
>>> r
[1, 2]
>>> ser
0    999
1      2
dtype: int64

Due to input data type the Series has a `copy` of
the original data even though `copy=False`, so
the data is unchanged.

Constructing Series from a 1d ndarray with `copy=False`.

>>> r = np.array([1, 2])
>>> ser = pd.Series(r, copy=False)
>>> ser.iloc[0] = 999
>>> r
array([999,   2])
>>> ser
0    999
1      2
dtype: int64

Due to input data type the Series has a `view` on
the original data, so
the data is changed as well.



a=pd.read_csv("movies.csv")
print(a)




#Q1  Read a csv file in pandas and select 1 coloumn and count how many time the value is present there

find unique values

drop duplicate value from any coloumn

change integre coloumn to float data type

a=pd.read_csv("links.csv")
values_count =a["movieId"].value_counts()
print(values_count)

#second answer
unique_count =a ["movieId"].unique()
print(unique_count)
#third answer
duplicate= a["movieId"].drop_duplicates()
print(duplicate)
#fourth answer
float_type =a["movieId"].astype(float)
print(float_type)













